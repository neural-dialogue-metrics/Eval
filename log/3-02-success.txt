ssh://cgsdfc@192.168.1.175:22/home/cgsdfc/miniconda3/envs/metrics-env/bin/python -u /home/cgsdfc/tmp/pycharm_project_658/evaluation/udc_bundle/run.py
INFO:evaluation.udc_bundle.estimator:our_dir: /tmp/tmpksju1sf0
INFO:evaluation.udc_bundle.estimator:added metric average
INFO:evaluation.udc_bundle.estimator:added metric greedy-matching
INFO:evaluation.udc_bundle.estimator:added metric extrema
INFO:evaluation.udc_bundle.estimator:added metric ROUGE-L
INFO:evaluation.udc_bundle.estimator:added metric ROUGE-W
INFO:evaluation.udc_bundle.estimator:added metric ROUGE-1
INFO:evaluation.udc_bundle.estimator:added metric ROUGE-2
INFO:evaluation.udc_bundle.estimator:added metric ROUGE-3
INFO:evaluation.udc_bundle.estimator:added metric ROUGE-4
INFO:evaluation.udc_bundle.estimator:added metric BLEU-1
INFO:evaluation.udc_bundle.estimator:added metric BLEU-2
INFO:evaluation.udc_bundle.estimator:added metric BLEU-3
INFO:evaluation.udc_bundle.estimator:added metric BLEU-4
INFO:evaluation.udc_bundle.estimator:added metric Distinct-1
INFO:evaluation.udc_bundle.estimator:added metric Distinct-2
INFO:evaluation.udc_bundle.model:Found 3 models
INFO:evaluation.udc_bundle.model:Found model_dir: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/HRED_Baseline
INFO:evaluation.udc_bundle.model:Found model_dir: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/VHRED
INFO:evaluation.udc_bundle.model:Found model_dir: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/LSTM_Baseline
INFO:evaluation.udc_bundle.model:Found model responses file: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/HRED_Baseline/HRED_BeamSearch_5_GeneratedTestResponses.txt
INFO:evaluation.udc_bundle.model:Found model responses file: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/HRED_Baseline/HRED_BeamSearch_5_GeneratedTestResponses.txt_First.txt
INFO:evaluation.udc_bundle.model:Created ModelInfo <Model HRED_Baseline>
INFO:evaluation.udc_bundle.model:Found model responses file: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/VHRED/First_VHRED_BeamSearch_5_GeneratedTestResponses.txt_First.txt
INFO:evaluation.udc_bundle.model:Found model responses file: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/VHRED/First_VHRED_BeamSearch_5_GeneratedTestResponses.txt
INFO:evaluation.udc_bundle.model:Created ModelInfo <Model VHRED>
INFO:evaluation.udc_bundle.model:Found model responses file: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/LSTM_Baseline/LSTM_BeamSearch_5_GeneratedTestResponses.txt_First.txt
INFO:evaluation.udc_bundle.model:Found model responses file: /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/LSTM_Baseline/LSTM_BeamSearch_5_GeneratedTestResponses.txt
INFO:evaluation.udc_bundle.model:Created ModelInfo <Model LSTM_Baseline>
INFO:evaluation.udc_bundle.estimator:added model HRED_Baseline
INFO:evaluation.udc_bundle.estimator:added model VHRED
INFO:evaluation.udc_bundle.estimator:added model LSTM_Baseline
INFO:evaluation.udc_bundle.estimator:number of models: 3
INFO:evaluation.udc_bundle.estimator:number of metrics: 15
INFO:evaluation.udc_bundle.estimator:number of combinations: 45
INFO:evaluation.udc_bundle.estimator:scheduling metrics...
INFO:evaluation.udc_bundle.estimator:Metric Schedule:
INFO:evaluation.udc_bundle.estimator:DistinctN: Distinct-1, Distinct-2
INFO:evaluation.udc_bundle.estimator:RougeL: ROUGE-L
INFO:evaluation.udc_bundle.estimator:RougeW: ROUGE-W
INFO:evaluation.udc_bundle.estimator:RougeN: ROUGE-1, ROUGE-2, ROUGE-3, ROUGE-4
INFO:evaluation.udc_bundle.estimator:BleuScore: BLEU-1, BLEU-2, BLEU-3, BLEU-4
INFO:evaluation.udc_bundle.estimator:AverageScore: average
INFO:evaluation.udc_bundle.estimator:GreedyMatchingScore: greedy-matching
INFO:evaluation.udc_bundle.estimator:ExtremaScore: extrema
INFO:evaluation.udc_bundle.estimator:Metric Schedule End
INFO:evaluation.udc_bundle.estimator:Evaluating Model HRED_Baseline
INFO:evaluation.udc_bundle.estimator:evaluating DistinctN on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.loader:loading response /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/HRED_Baseline/HRED_BeamSearch_5_GeneratedTestResponses.txt_First.txt
INFO:evaluation.udc_bundle.estimator:apply metric Distinct-1...
INFO:evaluation.udc_bundle.estimator:apply metric Distinct-2...
INFO:evaluation.udc_bundle.estimator:waiting for metric Distinct-1
INFO:evaluation.udc_bundle.estimator:done. metric Distinct-1: 0.8868486262310102
INFO:evaluation.udc_bundle.estimator:waiting for metric Distinct-2
INFO:evaluation.udc_bundle.estimator:done. metric Distinct-2: 0.7832569028833108
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-Distinct-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-Distinct-2.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeL on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.loader:loading reference /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/raw_testing_responses.txt
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-L...
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-L: 0.1956657719263226
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-ROUGE-L.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeW on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-W...
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-W: 0.13607477331401388
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-ROUGE-W.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeN on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-1...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-2...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-3...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-4...
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-1
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-1: 0.2054921189323177
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-2
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-2: 0.034198859490506
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-3
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-3: 0.004751704181289539
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-4
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-4: 0.0016526806198820848
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-ROUGE-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-ROUGE-2.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-ROUGE-3.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-ROUGE-4.txt
INFO:evaluation.udc_bundle.estimator:evaluating BleuScore on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-1...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-2...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-3...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-4...
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-1
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-1: BleuScore(bleu=0.08162494501921937, geo_mean=0.08162494501921937, precisions=[0.08162494501921937], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-2
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-2: BleuScore(bleu=0.001604469965098009, geo_mean=0.001604469965098009, precisions=[0.08162494501921937, 3.1538445364899814e-05], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-3
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-3: BleuScore(bleu=0.00031090305617964987, geo_mean=0.00031090305617964987, precisions=[0.08162494501921937, 3.1538445364899814e-05, 1.1673787677149728e-05], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-4
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-4: BleuScore(bleu=0.00011805038114471647, geo_mean=0.00011805038114471647, precisions=[0.08162494501921937, 3.1538445364899814e-05, 1.1673787677149728e-05, 6.462411384183894e-06], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-BLEU-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-BLEU-2.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-BLEU-3.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-BLEU-4.txt
INFO:evaluation.udc_bundle.estimator:evaluating AverageScore on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.loader:loading embeddings /home/cgsdfc/embeddings/GoogleNews-vectors-negative300.bin
INFO:gensim.models.utils_any2vec:loading projection weights from /home/cgsdfc/embeddings/GoogleNews-vectors-negative300.bin
INFO:gensim.models.utils_any2vec:loaded (3000000, 300) matrix from /home/cgsdfc/embeddings/GoogleNews-vectors-negative300.bin
INFO:evaluation.udc_bundle.estimator:apply metric average...
INFO:evaluation.udc_bundle.estimator:done. metric average: CorpusLevelScore(mean=0.56419603303023202, confidence_interval=2.20093935106077e-05, standard_deviation=0.20202601971905262)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-average.txt
INFO:evaluation.udc_bundle.estimator:evaluating GreedyMatchingScore on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric greedy-matching...
INFO:evaluation.udc_bundle.estimator:done. metric greedy-matching: CorpusLevelScore(mean=0.41683765690680213, confidence_interval=1.9238725123635573e-05, standard_deviation=0.18571259149958422)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-greedy-matching.txt
INFO:evaluation.udc_bundle.estimator:evaluating ExtremaScore on HRED_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric extrema...
INFO:evaluation.udc_bundle.estimator:done. metric extrema: CorpusLevelScore(mean=0.33270293983101346, confidence_interval=1.6692572627780502e-05, standard_deviation=0.15322248680938724)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/HRED_Baseline-extrema.txt
INFO:evaluation.udc_bundle.estimator:Evaluating Model VHRED
INFO:evaluation.udc_bundle.estimator:evaluating DistinctN on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.loader:loading response /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/VHRED/First_VHRED_BeamSearch_5_GeneratedTestResponses.txt_First.txt
INFO:evaluation.udc_bundle.estimator:apply metric Distinct-1...
INFO:evaluation.udc_bundle.estimator:apply metric Distinct-2...
INFO:evaluation.udc_bundle.estimator:waiting for metric Distinct-1
INFO:evaluation.udc_bundle.estimator:done. metric Distinct-1: 0.9398442763427736
INFO:evaluation.udc_bundle.estimator:waiting for metric Distinct-2
INFO:evaluation.udc_bundle.estimator:done. metric Distinct-2: 0.8072900787719915
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-Distinct-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-Distinct-2.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeL on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-L...
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-L: 0.18004588229429538
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-ROUGE-L.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeW on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-W...
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-W: 0.12504357824380302
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-ROUGE-W.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeN on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-1...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-2...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-3...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-4...
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-1
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-1: 0.18877719837896834
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-2
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-2: 0.02318028099923193
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-3
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-3: 0.002869532860870348
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-4
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-4: 0.0007011367750691444
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-ROUGE-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-ROUGE-2.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-ROUGE-3.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-ROUGE-4.txt
INFO:evaluation.udc_bundle.estimator:evaluating BleuScore on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-1...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-2...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-3...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-4...
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-1
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-1: BleuScore(bleu=0.07588753325382994, geo_mean=0.07588753325382994, precisions=[0.07588753325382992], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-2
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-2: BleuScore(bleu=0.0009879628291101453, geo_mean=0.0009879628291101453, precisions=[0.07588753325382992, 1.2862067191439009e-05], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-3
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-3: BleuScore(bleu=0.00019262039703573267, geo_mean=0.00019262039703573267, precisions=[0.07588753325382992, 1.2862067191439009e-05, 7.321930646672915e-06], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-4
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-4: BleuScore(bleu=0.0, geo_mean=0, precisions=[0.07588753325382992, 1.2862067191439009e-05, 7.321930646672915e-06, 0.0], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-BLEU-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-BLEU-2.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-BLEU-3.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-BLEU-4.txt
INFO:evaluation.udc_bundle.estimator:evaluating AverageScore on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric average...
INFO:evaluation.udc_bundle.estimator:done. metric average: CorpusLevelScore(mean=0.53011436379526922, confidence_interval=2.2220986048605174e-05, standard_deviation=0.20183684419557035)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-average.txt
INFO:evaluation.udc_bundle.estimator:evaluating GreedyMatchingScore on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric greedy-matching...
INFO:evaluation.udc_bundle.estimator:done. metric greedy-matching: CorpusLevelScore(mean=0.38376092424789343, confidence_interval=1.8346932808371683e-05, standard_deviation=0.17710406568081238)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-greedy-matching.txt
INFO:evaluation.udc_bundle.estimator:evaluating ExtremaScore on VHRED...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric extrema...
INFO:evaluation.udc_bundle.estimator:done. metric extrema: CorpusLevelScore(mean=0.30501130570420826, confidence_interval=1.5428842567609136e-05, standard_deviation=0.14014269603629873)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/VHRED-extrema.txt
INFO:evaluation.udc_bundle.estimator:Evaluating Model LSTM_Baseline
INFO:evaluation.udc_bundle.estimator:evaluating DistinctN on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.loader:loading response /home/cgsdfc/UbuntuDialogueCorpus/ResponseContextPairs/ModelPredictions/LSTM_Baseline/LSTM_BeamSearch_5_GeneratedTestResponses.txt_First.txt
INFO:evaluation.udc_bundle.estimator:apply metric Distinct-1...
INFO:evaluation.udc_bundle.estimator:apply metric Distinct-2...
INFO:evaluation.udc_bundle.estimator:waiting for metric Distinct-1
INFO:evaluation.udc_bundle.estimator:done. metric Distinct-1: 0.9697719416376996
INFO:evaluation.udc_bundle.estimator:waiting for metric Distinct-2
INFO:evaluation.udc_bundle.estimator:done. metric Distinct-2: 0.623211532419325
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-Distinct-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-Distinct-2.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeL on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-L...
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-L: 0.19289301500076259
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-ROUGE-L.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeW on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-W...
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-W: 0.1376520360385548
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-ROUGE-W.txt
INFO:evaluation.udc_bundle.estimator:evaluating RougeN on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-1...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-2...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-3...
INFO:evaluation.udc_bundle.estimator:apply metric ROUGE-4...
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-1
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-1: 0.19593789634091227
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-2
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-2: 0.028954895934086785
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-3
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-3: 0.001632836907412627
INFO:evaluation.udc_bundle.estimator:waiting for metric ROUGE-4
INFO:evaluation.udc_bundle.estimator:done. metric ROUGE-4: 0.0005115307192316384
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-ROUGE-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-ROUGE-2.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-ROUGE-3.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-ROUGE-4.txt
INFO:evaluation.udc_bundle.estimator:evaluating BleuScore on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-1...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-2...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-3...
INFO:evaluation.udc_bundle.estimator:apply metric BLEU-4...
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-1
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-1: BleuScore(bleu=0.08016746974520322, geo_mean=0.08016746974520322, precisions=[0.08016746974520321], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-2
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-2: BleuScore(bleu=0.0, geo_mean=0, precisions=[0.08016746974520321, 0.0], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-3
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-3: BleuScore(bleu=0.0, geo_mean=0, precisions=[0.08016746974520321, 0.0, 0.0], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:waiting for metric BLEU-4
INFO:evaluation.udc_bundle.estimator:done. metric BLEU-4: BleuScore(bleu=0.0, geo_mean=0, precisions=[0.08016746974520321, 0.0, 0.0, 0.0], brevity_penalty=1.0)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-BLEU-1.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-BLEU-2.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-BLEU-3.txt
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-BLEU-4.txt
INFO:evaluation.udc_bundle.estimator:evaluating AverageScore on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric average...
INFO:evaluation.udc_bundle.estimator:done. metric average: CorpusLevelScore(mean=0.52311586783962982, confidence_interval=5.2047745100662516e-05, standard_deviation=0.20338453047243582)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-average.txt
INFO:evaluation.udc_bundle.estimator:evaluating GreedyMatchingScore on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric greedy-matching...
INFO:evaluation.udc_bundle.estimator:done. metric greedy-matching: CorpusLevelScore(mean=0.16883265799548666, confidence_interval=2.3790868085493043e-05, standard_deviation=0.2296547062130247)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-greedy-matching.txt
INFO:evaluation.udc_bundle.estimator:evaluating ExtremaScore on LSTM_Baseline...
INFO:evaluation.udc_bundle.estimator:loading signature...
INFO:evaluation.udc_bundle.estimator:apply metric extrema...
INFO:evaluation.udc_bundle.estimator:done. metric extrema: CorpusLevelScore(mean=0.30687835514543388, confidence_interval=3.8524198673251332e-05, standard_deviation=0.15053920287675099)
INFO:evaluation.udc_bundle.estimator:saving result to /tmp/tmpksju1sf0/LSTM_Baseline-extrema.txt
INFO:evaluation.udc_bundle.estimator:all evaluation done
INFO:evaluation.udc_bundle.estimator:writing summary to /tmp/tmpksju1sf0/summary.csv...

Process finished with exit code 0
